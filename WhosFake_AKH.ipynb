{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WhosFake_AKH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KampHost/caldiss/blob/master/WhosFake_AKH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx7wEOIM3X_v",
        "colab_type": "text"
      },
      "source": [
        "#FakeTrump"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSUy5k-Z4e8t",
        "colab_type": "text"
      },
      "source": [
        "Setup\n",
        "1. Load libraries for preprocessing data\n",
        "2. Load and preproces data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLBo_zuF5YNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1) #to see more text\n",
        "\n",
        "import numpy as np\n",
        "import spacy\n",
        "nlp = spacy.load(\"en\")\n",
        "\n",
        "import itertools\n",
        "from collections import Counter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2mH-Gvv30it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FakeTrump = pd.read_csv('https://raw.githubusercontent.com/DeepLearnI/trump_tweet_classifier/master/code/tweet_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKbs9oMP39UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FakeTrump.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDd8W94K6W0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = pd.DataFrame(pd.get_dummies(FakeTrump.labels)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMVK_lmVc2Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filter the corpus using tweet-preprocessor\n",
        "! pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.HASHTAG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdvYS7YSc3FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clean up tweets\n",
        "clean_tweet = FakeTrump['tweet'].map(p.clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJvzllbudGMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_tweet=pd.DataFrame(clean_tweet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQpR2q0P7o_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SPACY tokenizer\n",
        "import spacy\n",
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX6BcBQik4nG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "for tweet in nlp.pipe(clean_tweet['tweet']):\n",
        "  FT_tok = [token.lemma_.lower() for token in tweet if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'ADV'] and not token.is_stop and not token.is_digit]\n",
        "  X.append(FT_tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipF1-jquXZMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Alternative Tokenizer \n",
        "# Tokenizing Tweets made easy!\n",
        "#from nltk.tokenize import TweetTokenizer\n",
        "#tknzr = TweetTokenizer()\n",
        "#import nltk #this part is needed on colab.\n",
        "#nltk.download('stopwords')\n",
        "#from nltk.corpus import stopwords\n",
        "#stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sZYao7uiuP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the tweets and remove stopwords\n",
        "#train_tokens = train_df['review'].map(lambda t: [tok.lower() for tok in word_tokenize(t) if tok not in stop_words and tok.isalpha()])\n",
        "#X = clean_tweet['tweet'].map(lambda textline: [tweet for tweet in tknzr.tokenize(textline) if tweet not in stop_words and tweet.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E08PaUIDWzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwp_02O4EB17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y['tokens'] = X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIxmDgh_F4yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FakeTrump_new = y[y['tokens'].map(len) >0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma8t58wMGgpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=FakeTrump_new['tokens']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lv5LvBmGkQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=FakeTrump_new.iloc[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXp6GbkD0D93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data using the train_test_split module. We keep 20% of the data for testing and use 80% to train the model\n",
        "# Random state defined with an arbitrary number for reproducibility\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45IJcPtKDHRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgzUmOHbDOYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMxRdLNYDQaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jahrNGrNDR1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH38hUmp4w5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qq -U gensim\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJdbKL1K1aBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a dictionary\n",
        "dictionary = Dictionary(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh5uSZC_1mFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct corpus using this dictionary\n",
        "train_corpus = [dictionary.doc2bow(doc) for doc in X_train]\n",
        "test_corpus = [dictionary.doc2bow(doc) for doc in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48jTjj2X1rj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tooling to map between corpus (gensim) and matrix - more general\n",
        "from gensim.matutils import corpus2csc, corpus2dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGPc2pNY1vM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = corpus2csc(train_corpus)\n",
        "X_test = corpus2csc(test_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0XNcFUh100s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMkYg0MToSFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train.T, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X27FRi_YAAkH",
        "colab_type": "code",
        "outputId": "9dabc34d-c619-4c39-c4fc-0ca525814b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.score(X_test.T, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7070234113712375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}